{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Analysis Notebook\n",
    "\n",
    "Use this notebook to generate the likelihood profiles from Gaia data using the Bayesian distance inferences described in  \n",
    "Bailer - Jones (C. A. L. Bailer-Jones et al 2018 AJ 156 58): https://iopscience.iop.org/article/10.3847/1538-3881/aacb21.  \n",
    "\n",
    "Specify the path variable to your own data path and run the cells. The likelihood value generation can take a while if data  \n",
    "set is very large. Also pay attention to the minimum and maximum bin edge values in the 'get_likelihood_sum' function.  \n",
    "Depending on the data used they might need to be tuned.  \n",
    "\n",
    "The plots included in this notebook were generated with the spectroscopic data where using default $R_0$, $z_0$, $U_\\odot$, $V_\\odot$, $W_\\odot$:\n",
    "   * 0 < r < 15 kpc\n",
    "   * -2 < z < 2 kpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "sys.path.append(\"../gaia_tools/\")\n",
    "import data_analysis\n",
    "import transformation_constants\n",
    "import covariance_generation\n",
    "from import_functions import import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start import...\n",
      "The dimensions of the data: (rows, columns) -> (7133471, 24)\n",
      "Checking indexing... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/hdfs/local/sven/gaia_tools_data/gaia_rv_data_bayes.csv\"\n",
    "data_icrs = import_data(path = path, debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIKELIHOOD SUM FUNCTION\n",
    "'''\n",
    "This function uses the Gaia data in ICRS:\n",
    "1) Transforms it into a Galactocentric frame using the theta arguments given\n",
    "2) Generates the covariance matrices (also transforms) and appends them to the Galactocentric data\n",
    "3) Bins the data and generates a 'BinCollection' object\n",
    "4) Iterates over the bins and computes a likelihood value for each\n",
    "5) Sums the likelihood values over the bins\n",
    "'''\n",
    "\n",
    "def get_likelihood_sum(data_icrs, \n",
    "                       r = transformation_constants.R_0, \n",
    "                       z = transformation_constants.Z_0, \n",
    "                       Usun = transformation_constants.V_SUN[0][0],\n",
    "                       Vsun = transformation_constants.V_SUN[1][0],\n",
    "                       num_r_bin = 10,\n",
    "                       num_z_bin = 4):\n",
    " \n",
    "    start = time.time()\n",
    "    theta = (r, z, Usun, Vsun, transformation_constants.V_SUN[2][0])\n",
    "    \n",
    "    v_sun = np.array([[theta[2]], \n",
    "                              [theta[3]], \n",
    "                              [theta[4]]])\n",
    "   \n",
    "    # 1\n",
    "    galcen_data = data_analysis.get_transformed_data(data_icrs, \n",
    "                                       include_cylindrical = True, \n",
    "                                       r_0 = theta[0],\n",
    "                                       v_sun = v_sun,\n",
    "                                       debug = True,\n",
    "                                       is_bayes = True, \n",
    "                                       is_source_included = True)\n",
    "    # 2\n",
    "    cov_df = covariance_generation.generate_covmatrices(df = data_icrs, \n",
    "                                           df_crt = galcen_data, \n",
    "                                           transform_to_galcen = True, \n",
    "                                           transform_to_cylindrical = True,\n",
    "                                           z_0 = theta[1],\n",
    "                                           r_0 = theta[0],\n",
    "                                           is_bayes = True,\n",
    "                                           debug=True)\n",
    "    \n",
    "    galcen_data['cov_mat'] = cov_df['cov_mat']\n",
    "    \n",
    "    min_val = np.min(galcen_data.r)\n",
    "    max_val = np.max(galcen_data.r)\n",
    "    \n",
    "    min_val_z = np.min(galcen_data.z)\n",
    "    max_val_z = np.max(galcen_data.z)\n",
    "    \n",
    "    # 3\n",
    "    bin_collection = data_analysis.get_collapsed_bins(data = galcen_data, \n",
    "                                                                 theta = theta, \n",
    "                                                                 BL_r_min = min_val - 1, \n",
    "                                                                 BL_r_max = max_val + 1, \n",
    "                                                                 BL_z_min = -1200, \n",
    "                                                                 BL_z_max = 1200, \n",
    "                                                                 N_bins = (num_r_bin, num_z_bin ),\n",
    "                                                                 r_drift = False, \n",
    "                                                                 debug = True)\n",
    "\n",
    "    # Computes the MLE Mu and Sigma for each bin\n",
    "    bin_collection.GetMLEParameters()\n",
    "    \n",
    "    # Setup likelihood array\n",
    "    n = reduce(lambda x, y: x*y, bin_collection.N_bins)\n",
    "    likelihood_array = np.zeros(n)\n",
    "\n",
    "    star_count = len(bin_collection.data)\n",
    "\n",
    "    # Keep track how many data points are used in likelihood computation\n",
    "    point_count = []\n",
    "    \n",
    "    # 4\n",
    "    for i, bin in enumerate(bin_collection.bins):\n",
    "        \n",
    "        likelihood_value = bin.get_bin_likelihood(debug=True)\n",
    "        \n",
    "        if(likelihood_value == 0):\n",
    "            print(theta)\n",
    "            val = 0\n",
    "                    \n",
    "        else:            \n",
    "            #print(bin.N_points)\n",
    "            point_count.append(bin.N_points)\n",
    "            \n",
    "            # get bin likelihood\n",
    "            val = likelihood_value\n",
    "\n",
    "            # convert chi-squared\n",
    "            #val = val*(-2)/star_count\n",
    "\n",
    "        likelihood_array[i] = val\n",
    "    \n",
    "    print(\"Number of points in analysis: {0}\".format(np.sum(point_count)))\n",
    "    print(\"Bin Collection data shape: {0}\".format(bin_collection.data.shape))\n",
    "    \n",
    "    likelihood_sum = np.sum(likelihood_array)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Likelihood time = %s\" % (end - start))\n",
    "    \n",
    "    return likelihood_sum, bin_collection, likelihood_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that generates the neccessary variables for \n",
    "# plotting the profiles\n",
    "\n",
    "def generate_plot_vars(bin_r, bin_z, parameter):\n",
    "    \n",
    "    # The varied range in x-axis    \n",
    "    if(parameter == \"R_0\"):\n",
    "        x = np.linspace(6000, 12000, 10)\n",
    "    elif(parameter == \"U_odot\"):\n",
    "        x = np.linspace(0, 50, 10)\n",
    "    else:\n",
    "        x = np.linspace(150, 350, 10)\n",
    "    \n",
    "    # The likelihood values\n",
    "    y = []\n",
    "\n",
    "    for i, item in enumerate(x):\n",
    "        print(i, item)\n",
    "        \n",
    "        if(parameter == \"R_0\"):\n",
    "            val = get_likelihood_sum(data_icrs, \n",
    "                                    r = item,\n",
    "                                    num_r_bin = bin_r,\n",
    "                                    num_z_bin = bin_z)[0]\n",
    "                    \n",
    "        elif(parameter == \"U_odot\"):\n",
    "        \n",
    "            val = get_likelihood_sum(data_icrs, \n",
    "                                    Usun = item,\n",
    "                                    num_r_bin = bin_r,\n",
    "                                    num_z_bin = bin_z)[0]\n",
    "            \n",
    "        elif(parameter == \"V_odot\"):\n",
    "            val = get_likelihood_sum(data_icrs,\n",
    "                                    Vsun = item,\n",
    "                                    num_r_bin = bin_r,\n",
    "                                    num_z_bin = bin_z)[0]\n",
    "        \n",
    "        print(\"Likelihood: {0}\".format(val))\n",
    "        y.append(val)\n",
    "\n",
    "    return x, y, parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plotting function\n",
    "\n",
    "def generate_likelihood_plot(x, y, bin_r, bin_z, parameter, save = False):\n",
    "    \n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    plt.plot(x, y, '-', color='blue')\n",
    "    plt.title(\"Likelihood dependence on ${0}$\".format(parameter), pad = 45, fontdict={'fontsize': 20})\n",
    "    plt.suptitle(r\"({0}x{1} bins)\".format(bin_r, bin_z), y=0.93, fontsize=15)\n",
    "    plt.grid()\n",
    "\n",
    "    #plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    #plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "\n",
    "    if(parameter == \"R_0\"):\n",
    "        unit = \"pc\"\n",
    "    else:\n",
    "        unit = \"km/s\"\n",
    "    \n",
    "    plt.xlabel(r'${0}$ [{1}]'.format(parameter, unit), fontdict={'fontsize': 18}, labelpad = 25)\n",
    "    plt.ylabel('Log Likelihood',fontdict={'fontsize': 18}, labelpad = 25)\n",
    "    plt.subplots_adjust(left=0.2)\n",
    "\n",
    "    title_string = \"../out/Likelihood_{0}_{1}x{2}\".format(parameter, bin_r, bin_z)\n",
    "\n",
    "    if(save):\n",
    "        plt.savefig(title_string+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## $R_0$ Likelihood\n",
    "$R_0$ is varied, rest of the parameters are fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = \"R_0\"\n",
    "bin_r = 10\n",
    "bin_z = 4\n",
    "x_R0, y_R0, parameter = generate_plot_vars(bin_r, bin_z, parameter)\n",
    "\n",
    "generate_likelihood_plot(x_R0, y_R0, bin_r, bin_z, parameter)\n",
    "#plt.ylabel('Reduced $\\chi^2$',fontdict={'fontsize': 18}, labelpad = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## $U_\\odot$ Likelihood\n",
    "$U_\\odot$ is varied, rest of the parameters are fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = \"U_odot\"\n",
    "\n",
    "bin_r = 10\n",
    "bin_z = 4\n",
    "\n",
    "x, y, parameter = generate_plot_vars(bin_r, bin_z, parameter)\n",
    "generate_likelihood_plot(x, y, bin_r, bin_z, parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## $V_\\odot$ Likelihood\n",
    "$V_\\odot$ is varied, rest of the parameters are fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = \"V_odot\"\n",
    "\n",
    "bin_r = 10\n",
    "bin_z = 4\n",
    "\n",
    "x, y, parameter = generate_plot_vars(bin_r, bin_z, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_likelihood_plot(x, y, bin_r, bin_z, parameter)\n",
    "\n",
    "# Reid & Brunthaler + GRAVITY: 245.6 +- 1.4 [km/s]\n",
    "v_circ = 245.6\n",
    "plt.axvline(x=v_circ, label=\"Reid & Brunthaler + GRAVITY\\n (2020)\")\n",
    "plt.axvline(x=v_circ+1.4, ls=\"--\")\n",
    "plt.axvline(x=v_circ-1.4, ls=\"--\")\n",
    "\n",
    "plt.xlim(175, 325)\n",
    "plt.legend()\n",
    "#plt.savefig('../out/Vodot_profile'+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
