{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Analysis with Asymmetric Drift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "sys.path.append(\"../gaia_tools/\")\n",
    "import data_analysis\n",
    "import transformation_constants\n",
    "import covariance_generation\n",
    "from import_functions import import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/hdfs/local/sven/gaia_tools_data/gaia_rv_data_bayes.csv\"\n",
    "data_icrs = import_data(path = path, debug = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing data to smaller sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galcen_data = data_analysis.get_transformed_data(data_icrs,\n",
    "                                       include_cylindrical = True,\n",
    "                                       debug = True,\n",
    "                                       is_bayes = True,\n",
    "                                       is_source_included = True)\n",
    "\n",
    "cov_df = covariance_generation.generate_covmatrices(df = data_icrs,\n",
    "                                       df_crt = galcen_data,\n",
    "                                       transform_to_galcen = True,\n",
    "                                       transform_to_cylindrical = True,\n",
    "                                       is_bayes = True,\n",
    "                                       debug=False)\n",
    "\n",
    "# append covariance information to galactocentric data\n",
    "galcen_data['cov_mat'] = cov_df['cov_mat']\n",
    "\n",
    "galcen_data = galcen_data[(galcen_data.r < 12000) & (galcen_data.r > 5000)]\n",
    "galcen_data = galcen_data[(galcen_data.z < 200) & (galcen_data.z > -200)]\n",
    "galcen_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "data_icrs = data_icrs.merge(galcen_data, on='source_id')[data_icrs.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIKELIHOOD SUM FUNCTION\n",
    "'''\n",
    "This function uses the Gaia data in ICRS:\n",
    "1) Transforms it into a Galactocentric frame using the theta arguments given\n",
    "2) Generates the covariance matrices (also transforms) and appends them to the Galactocentric data\n",
    "3) Bins the data and generates a 'BinCollection' object\n",
    "4) Iterates over the bins and computes a likelihood value for each\n",
    "5) Sums the likelihood values over the bins\n",
    "'''\n",
    "\n",
    "def get_likelihood_sum(data_icrs,\n",
    "                       theta,\n",
    "                       r = transformation_constants.R_0, \n",
    "                       z = transformation_constants.Z_0, \n",
    "                       Usun = transformation_constants.V_SUN[0][0],\n",
    "                       Vsun = transformation_constants.V_SUN[1][0],\n",
    "                       num_r_bin = 10,\n",
    "                       num_z_bin = 4):\n",
    " \n",
    "    \n",
    "    v_sun = np.array([[transformation_constants.V_SUN[0][0]],\n",
    "                     [theta[-1]],\n",
    "                     [transformation_constants.V_SUN[2][0]]])\n",
    "    # 1\n",
    "    galcen_data = data_analysis.get_transformed_data(data_icrs, \n",
    "                                       v_sun = v_sun,\n",
    "                                       include_cylindrical = True,\n",
    "                                       debug = True,\n",
    "                                       is_bayes = True, \n",
    "                                       is_source_included = True)\n",
    "    \n",
    "    # 2\n",
    "    cov_df = covariance_generation.generate_covmatrices(df = data_icrs, \n",
    "                                           df_crt = galcen_data,\n",
    "                                           transform_to_galcen = True, \n",
    "                                           transform_to_cylindrical = True,\n",
    "                                           is_bayes = True,\n",
    "                                           is_unpack_velocity = True,\n",
    "                                           debug=True)\n",
    "    \n",
    "    galcen_data = galcen_data.merge(cov_df, on='source_id')\n",
    "\n",
    "    min_val = np.min(galcen_data.r)\n",
    "    max_val = np.max(galcen_data.r)\n",
    "    \n",
    "    # 3\n",
    "    bin_collection = data_analysis.get_collapsed_bins(data = galcen_data, \n",
    "                                                        theta = theta, \n",
    "                                                        BL_r_min = min_val - 1, \n",
    "                                                        BL_r_max = max_val + 1, \n",
    "                                                        BL_z_min = -200, \n",
    "                                                        BL_z_max = 200, \n",
    "                                                        N_bins = (num_r_bin, num_z_bin ),\n",
    "                                                        r_drift = False, \n",
    "                                                        debug = True)\n",
    "\n",
    "\n",
    "    # Setup likelihood array\n",
    "    n = reduce(lambda x, y: x*y, bin_collection.N_bins)\n",
    "    likelihood_array = np.zeros(n)\n",
    "\n",
    "    # Keep track how many data points are used in likelihood computation\n",
    "    point_count = []\n",
    "    \n",
    "    # 4\n",
    "    start = time.time()\n",
    "    for i, bin in enumerate(bin_collection.bins):\n",
    "        point_count.append(bin.N_points)\n",
    "        \n",
    "        # We need the median of the variance in v_phi and \"A\" parameter \n",
    "        # to take into account the asymmetric drift\n",
    "        bin.med_sig_vphi = np.median(bin.data.sig_vphi)\n",
    "        bin.A_parameter = bin.compute_A_parameter()\n",
    "\n",
    "        # get bin likelihood\n",
    "        likelihood_value = bin.get_likelihood_w_asymmetry(theta[i], debug=False)\n",
    "        likelihood_array[i] = likelihood_value\n",
    "        \n",
    "    print(\"Number of points in analysis: {0}\".format(np.sum(point_count)))\n",
    "    print(\"Bin Collection data shape: {0}\".format(bin_collection.data.shape))\n",
    "    \n",
    "    likelihood_sum = np.sum(likelihood_array)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Likelihood time = %s\" % (end - start))\n",
    "    \n",
    "    return likelihood_sum, bin_collection, likelihood_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plotting function\n",
    "\n",
    "def generate_likelihood_plot(x, y, bin_r, bin_z, parameter, save = False):\n",
    "    \n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    plt.plot(x, y, '-', color='blue')\n",
    "    plt.title(\"Likelihood dependence on ${0}$\".format(parameter), pad = 45, fontdict={'fontsize': 20})\n",
    "    plt.suptitle(r\"({0}x{1} bins)\".format(bin_r, bin_z), y=0.93, fontsize=15)\n",
    "    plt.grid()\n",
    "\n",
    "    idx_max = np.argmax(y)\n",
    "    plt.axvline(x=x[idx_max], ls=\"--\", label=\"Max\")\n",
    "\n",
    "\n",
    "    if(parameter == \"R_0\"):\n",
    "        unit = \"pc\"\n",
    "    else:\n",
    "        unit = \"km/s\"\n",
    "    \n",
    "    plt.xlabel('${0}$ [{1}]'.format(parameter, unit), fontdict={'fontsize': 18}, labelpad = 25)\n",
    "    plt.ylabel('Log Likelihood',fontdict={'fontsize': 18}, labelpad = 25)\n",
    "    plt.subplots_adjust(left=0.2)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    title_string = \"../out/Likelihood_{0}_{1}x{2}\".format(parameter, bin_r, bin_z)\n",
    "\n",
    "    if(save):\n",
    "        plt.savefig(title_string+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## $V_{\\odot, TOT}$ Likelihood\n",
    "$V_{\\odot, TOT}$ is varied, rest of the parameters are fixed. In reality, we are reconstructing the circular velocity $v_c$ inside each bin along with $V_{\\odot, TOT}$. Theta is the set of parameters, where the last element is $V_{\\odot, TOT}$. So below I have fixed $v_c$ to some arbitrary value and inside the loop $V_{\\odot, TOT}$ is varied.\n",
    "\n",
    "The circular velocities are negative because we are using a right-handed transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [-210,-210, -210, -210, -210, 230]\n",
    "bin_r = 5\n",
    "bin_z = 1\n",
    "\n",
    "V_range = [value for value in range(150, 301, 10)]\n",
    "\n",
    "# The likelihood values\n",
    "y = []\n",
    "\n",
    "for i, item in enumerate(V_range):\n",
    "    print(i, item)\n",
    "    theta[-1] = V_range[i]\n",
    "    val = get_likelihood_sum(data_icrs,\n",
    "                            theta,\n",
    "                            num_r_bin = bin_r,\n",
    "                            num_z_bin = bin_z)[0]\n",
    "\n",
    "    print(\"Likelihood: {0}\".format(val))\n",
    "    y.append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_likelihood_plot(V_range, y, bin_r, bin_z, \"V_\\odot\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
